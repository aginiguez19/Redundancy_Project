metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
rlang::last_trace()
# Initial values
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
# Array containing data
metrics <- array(NA, dim = c(nsim, (2*nv + 1), 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone"), c("strength", "closeness", "betweenness")))
for (i in 1:nsim){
lat_corr <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
# Correlation matrix of the latent variables
redun_corr <- ind_corr(matrix = lat_mat, loading = loading)
# Correlation matrix of the indicators with the inclusion of the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
# Correlation matrix of the indicators excluding the redundant indicator
true_pcor <- cor2pcor(true_corr)
# Partial correlation matrix of the indicators excluding the redundant indicator
redun_pcor <- cor2pcor(redun_corr)
# Partial correlation matrix of the indicators with the inclusion of the redundant indicator
one <- cbind(true_pcor, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
# Create a block for easier centrality computation
metrics[i,, "strength"] <- strength(the_g)
metrics[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
metrics
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
# Initial values
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
# Array containing data
metrics <- array(NA, dim = c(nsim, (2*nv + 1), 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone"), c("strength", "closeness", "betweenness")))
for (i in 1:nsim){
lat_corr <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
# Correlation matrix of the latent variables
redun_corr <- ind_corr(matrix = lat_mat, loading = loading)
# Correlation matrix of the indicators with the inclusion of the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
# Correlation matrix of the indicators excluding the redundant indicator
true_pcor <- cor2pcor(true_corr)
# Partial correlation matrix of the indicators excluding the redundant indicator
redun_pcor <- cor2pcor(redun_corr)
# Partial correlation matrix of the indicators with the inclusion of the redundant indicator
one <- cbind(true_pcor, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
# Create a block for easier centrality computation
metrics[i,, "strength"] <- strength(the_g)
metrics[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
metrics
metrics
# Initial values
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
# Array containing data
metrics <- array(NA, dim = c(nsim, (2*nv + 1), 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone"), c("strength", "closeness", "betweenness")))
for (i in 1:nsim){
lat_corr <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
# Correlation matrix of the latent variables
redun_corr <- ind_corr(matrix = lat_corr, loading = loading)
# Correlation matrix of the indicators with the inclusion of the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
# Correlation matrix of the indicators excluding the redundant indicator
true_pcor <- cor2pcor(true_corr)
# Partial correlation matrix of the indicators excluding the redundant indicator
redun_pcor <- cor2pcor(redun_corr)
# Partial correlation matrix of the indicators with the inclusion of the redundant indicator
one <- cbind(true_pcor, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
# Create a block for easier centrality computation
metrics[i,, "strength"] <- strength(the_g)
metrics[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
metrics
metrics
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
for (i in 1:nsim){
lat_corr <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
# Correlation matrix of the latent variables
redun_corr <- ind_corr(matrix = lat_corr, loading = loading)
# Correlation matrix of the indicators with the inclusion of the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
# Correlation matrix of the indicators excluding the redundant indicator
true_pcor <- cor2pcor(true_corr)
# Partial correlation matrix of the indicators excluding the redundant indicator
redun_pcor <- cor2pcor(redun_corr)
# Partial correlation matrix of the indicators with the inclusion of the redundant indicator
one <- cbind(true_pcor, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
# Create a block for easier centrality computation
metrics[i,, "strength"] <- strength(the_g)
metrics[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
metrics
for (i in 1:nsim){
true_mat <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
redun_mat <- hcsf(matrix = true_mat)
true_subset <- redun_mat[1:nv, 1:nv]
true_pcor_subset <- cor2pcor(true_subset)
redun_pcor <- cor2pcor(redun_mat)
# Create one block matrix for easy computation
one <- cbind(true_pcor_subset, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
colnames(the_g) <- c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone")
# qgraph plots and graph matrices
g1 = qgraph(true_pcor_subset, edge.labels = TRUE, DoNotPlot = TRUE)
if (i == 1){
g2 = qgraph(redun_pcor, edge.labels = TRUE, DoNotPlot = TRUE)
pp = averageLayout(g2)}
png(filename = paste0('/Users/abraham/Library/CloudStorage/Box/Redundancy_Project/R/Network Graphs/HCSF_Graph_', i, ".png"), width = 1000, height = 500)
par(mfrow = c(1, 2))
g1 = qgraph(true_pcor_subset, layout = pp[1:nv,], edge.labels = TRUE, theme = "colorblind", labels = colnames(the_g)[1:nv], maximum = 1, vsize = 11)
g2 = qgraph(redun_pcor,layout = pp, edge.labels = TRUE, theme = "colorblind", labels = colnames(the_g)[(nv+1):(2*nv + 1)], maximum = 1, vsize = 11)
graphics.off()
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
saveRDS(the_g, paste0('/Users/abraham/Library/CloudStorage/Box/Redundancy_Project/R/Graph Matrices/HCSF_File_', i, ".RDS"))
#Compute Strength, Closeness, and Betweenness
hcsf_all[i,, "strength"] <- strength(the_g)
hcsf_all[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
hcsf_all[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
if (!is.null(hcsf_all)) {
saveRDS(hcsf_all, paste0('/Users/abraham/Library/CloudStorage/Box/Redundancy_Project/R/Metrics/HCSF_', i , ".RDS"))
prev_file <- paste0('/Users/abraham/Library/CloudStorage/Box/Redundancy_Project/R/Metrics/HCSF_', i - 1, ".RDS")
if (file.exists(prev_file)) {
file.remove(prev_file)
}
} else {
message(paste0("Ope, this run had an error. Preserving simulation as of Replication ", i))
}
# Compute clone inclusion difference in redundancy network
total_strength <- strength(the_g)
connections_2_clone <- E(the_g)$weight[which(grepl("Clone", as_ids(E(the_g))))]
hcsf_wc[i,,"strength"] <- (total_strength[(nv+1):(2*nv)] - connections_2_clone) - total_strength[1:nv]
clone_edges <- E(the_g)[grepl("Clone", as_ids(E(the_g)))]
g_no_clone <- delete_edges(the_g, clone_edges)
closeness_wc <- closeness(g_no_clone, normalized = TRUE, weights = 1/abs(E(g_no_clone)$weight))
closeness_wthc <- closeness(the_g, normalized = TRUE, weights = 1/abs(E(the_g)$weight))
hcsf_wc[i,,"closeness"] <- closeness_wc[(nv+1):(2*nv)] - closeness_wthc[1:nv]
betweenness_wc <- betweenness(g_no_clone, normalized = FALSE, weights = 1/abs(E(g_no_clone)$weight))
betweenness_wthc <- betweenness(the_g, normalized = FALSE,  weights = 1/abs(E(the_g)$weight))
hcsf_wc[i,,"betweenness" ] <- betweenness_wc[(nv+1):(2*nv)] - betweenness_wthc[1:nv]
}
#  contains the full simulated data
hcsf_all
library(qgraph)
library(igraph)
source("00_project_functions.R")
# Initial values
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
# Array containing data
metrics <- array(NA, dim = c(nsim, (2*nv + 1), 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone"), c("strength", "closeness", "betweenness")))
for (i in 1:nsim){
lat_corr <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
# Correlation matrix of the latent variables
redun_corr <- ind_cor(matrix = lat_corr, loading = loading)
# Correlation matrix of the indicators with the inclusion of the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
# Correlation matrix of the indicators excluding the redundant indicator
true_pcor <- cor2pcor(true_corr)
# Partial correlation matrix of the indicators excluding the redundant indicator
redun_pcor <- cor2pcor(redun_corr)
# Partial correlation matrix of the indicators with the inclusion of the redundant indicator
one <- cbind(true_pcor, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
# Create a block for easier centrality computation
metrics[i,, "strength"] <- strength(the_g)
metrics[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
# Initial values
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
# Array containing data
metrics <- array(NA, dim = c(nsim, (2*nv + 1), 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone"), c("strength", "closeness", "betweenness")))
for (i in 1:nsim){
lat_corr <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
# Correlation matrix of the latent variables
redun_corr <- ind_corr(matrix = lat_corr, loading = loading)
# Correlation matrix of the indicators with the inclusion of the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
# Correlation matrix of the indicators excluding the redundant indicator
true_pcor <- cor2pcor(true_corr)
# Partial correlation matrix of the indicators excluding the redundant indicator
redun_pcor <- cor2pcor(redun_corr)
# Partial correlation matrix of the indicators with the inclusion of the redundant indicator
one <- cbind(true_pcor, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
# Create a block for easier centrality computation
metrics[i,, "strength"] <- strength(the_g)
metrics[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
library(qgraph)
library(igraph)
source("00_project_functions.R")
# Initial values
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
# Array containing data
metrics <- array(NA, dim = c(nsim, (2*nv + 1), 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone"), c("strength", "closeness", "betweenness")))
for (i in 1:nsim){
lat_corr <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
# Correlation matrix of the latent variables
redun_corr <- ind_corr(matrix = lat_corr, loading = loading)
# Correlation matrix of the indicators with the inclusion of the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
# Correlation matrix of the indicators excluding the redundant indicator
true_pcor <- cor2pcor(true_corr)
# Partial correlation matrix of the indicators excluding the redundant indicator
redun_pcor <- cor2pcor(redun_corr)
# Partial correlation matrix of the indicators with the inclusion of the redundant indicator
one <- cbind(true_pcor, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
# Create a block for easier centrality computation
metrics[i,, "strength"] <- strength(the_g)
metrics[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
# Correlation of Indicators + Redundant Indicator Function  ----------------------------------------------------------
ind_corr <- function(matrix, loading, scalar = 1){
# Lambda
dimensions <- dim(matrix)
lambda_matrix <- diag(x = loading, nrow = dimensions[1] + 1 , ncol = dimensions[2])
last_element <- nrow(lambda_matrix) * ncol(lambda_matrix)
lambda_matrix[last_element] <- loading
# Lambda * Psi * t(Lambda)
redun_mat <- lambda_matrix %*% matrix %*% t(lambda_matrix)
# Theta
dimensions_theta <- dim(redun_mat)
theta <- diag((x = 1 - (loading)^2), nrow = dimensions_theta[1], ncol = dimensions_theta[2])
redun_mat <- redun_mat + theta
redun_mat[1:nv,nv+1] <- scalar*redun_mat[1:nv,nv+1]
return(redun_mat)
}
# Initial values
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
# Array containing data
metrics <- array(NA, dim = c(nsim, (2*nv + 1), 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone"), c("strength", "closeness", "betweenness")))
for (i in 1:nsim){
lat_corr <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
# Correlation matrix of the latent variables
redun_corr <- ind_corr(matrix = lat_corr, loading = loading)
# Correlation matrix of the indicators with the inclusion of the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
# Correlation matrix of the indicators excluding the redundant indicator
true_pcor <- cor2pcor(true_corr)
# Partial correlation matrix of the indicators excluding the redundant indicator
redun_pcor <- cor2pcor(redun_corr)
# Partial correlation matrix of the indicators with the inclusion of the redundant indicator
one <- cbind(true_pcor, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
# Create a block for easier centrality computation
metrics[i,, "strength"] <- strength(the_g)
metrics[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
metrics
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
scalar <-  -1
# Initial values
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
scalar <-  -1
# Array containing data
metrics <- array(NA, dim = c(nsim, (2*nv + 1), 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone"), c("strength", "closeness", "betweenness")))
for (i in 1:nsim){
lat_corr <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
# Correlation matrix of the latent variables
redun_corr <- ind_corr(matrix = lat_corr, loading = loading)
# Correlation matrix of the indicators with the inclusion of the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
# Correlation matrix of the indicators excluding the redundant indicator
true_pcor <- cor2pcor(true_corr)
# Partial correlation matrix of the indicators excluding the redundant indicator
redun_pcor <- cor2pcor(redun_corr)
# Partial correlation matrix of the indicators with the inclusion of the redundant indicator
one <- cbind(true_pcor, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
# Create a block for easier centrality computation
metrics[i,, "strength"] <- strength(the_g)
metrics[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
metrics
# Initial values
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
scalar <-  -1
# Array containing data
metrics <- array(NA, dim = c(nsim, (2*nv + 1), 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone"), c("strength", "closeness", "betweenness")))
for (i in 1:nsim){
lat_corr <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
# Correlation matrix of the latent variables
redun_corr <- ind_corr(matrix = lat_corr, loading = loading, scalar = scalar)
# Correlation matrix of the indicators with the inclusion of the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
# Correlation matrix of the indicators excluding the redundant indicator
true_pcor <- cor2pcor(true_corr)
# Partial correlation matrix of the indicators excluding the redundant indicator
redun_pcor <- cor2pcor(redun_corr)
# Partial correlation matrix of the indicators with the inclusion of the redundant indicator
one <- cbind(true_pcor, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
# Create a block for easier centrality computation
metrics[i,, "strength"] <- strength(the_g)
metrics[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
metrics
# Initial values
nsim <- 10
nv <- 4
ep <- .9
EF <- .5
loading <- .9
scalar <-  1
# Array containing data
metrics <- array(NA, dim = c(nsim, (2*nv + 1), 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone"), c("strength", "closeness", "betweenness")))
for (i in 1:nsim){
lat_corr <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
# Correlation matrix of the latent variables
redun_corr <- ind_corr(matrix = lat_corr, loading = loading, scalar = scalar)
# Correlation matrix of the indicators with the inclusion of the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
# Correlation matrix of the indicators excluding the redundant indicator
true_pcor <- cor2pcor(true_corr)
# Partial correlation matrix of the indicators excluding the redundant indicator
redun_pcor <- cor2pcor(redun_corr)
# Partial correlation matrix of the indicators with the inclusion of the redundant indicator
one <- cbind(true_pcor, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
# Create a block for easier centrality computation
metrics[i,, "strength"] <- strength(the_g)
metrics[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
metrics[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
# Get centrality metrics
}
metrics
hcsf_all
# Functions needed
# corr_gen() ~ Obtain true network corr matrix
# cor2pcor() ~ Move from corr matrix to pcor matrix
#  contains the full simulated data
hcsf_all
# Functions needed
# corr_gen() ~ Obtain true network corr matrix
# cor2pcor() ~ Move from corr matrix to pcor matrix
#  contains the full simulated data
hcsf_all <- array(NA, dim = c(nsim, (2*nv + 1), 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone"), c("strength", "closeness", "betweenness")))
hcsf_wc <- array(NA, dim = c(nsim, nv, 3),
dimnames = list(NULL, c(paste0("P", 1:(nv-1)), "Target"), c("strength", "closeness", "betweenness")))
for (i in 1:nsim){
true_mat <- corr_gen(nv = nv, EF = EF, edge.probability = ep)
redun_mat <- hcsf(matrix = true_mat)
true_subset <- redun_mat[1:nv, 1:nv]
true_pcor_subset <- cor2pcor(true_subset)
redun_pcor <- cor2pcor(redun_mat)
# Create one block matrix for easy computation
one <- cbind(true_pcor_subset, diag(0, nv, nv+1))
two <- cbind(diag(0, nv+1, nv), redun_pcor)
the_g <- rbind(one, two)
colnames(the_g) <- c(paste0("P", 1:(nv-1)), "Target", paste0("P", 1:(nv-1), ".r"), "Target.r", "Clone")
# qgraph plots and graph matrices
g1 = qgraph(true_pcor_subset, edge.labels = TRUE, DoNotPlot = TRUE)
if (i == 1){
g2 = qgraph(redun_pcor, edge.labels = TRUE, DoNotPlot = TRUE)
pp = averageLayout(g2)}
png(filename = paste0('/Users/abraham/Library/CloudStorage/Box/Redundancy_Project/R/Network Graphs/HCSF_Graph_', i, ".png"), width = 1000, height = 500)
par(mfrow = c(1, 2))
g1 = qgraph(true_pcor_subset, layout = pp[1:nv,], edge.labels = TRUE, theme = "colorblind", labels = colnames(the_g)[1:nv], maximum = 1, vsize = 11)
g2 = qgraph(redun_pcor,layout = pp, edge.labels = TRUE, theme = "colorblind", labels = colnames(the_g)[(nv+1):(2*nv + 1)], maximum = 1, vsize = 11)
graphics.off()
the_g <- graph_from_adjacency_matrix(the_g, mode = "undirected", weighted = TRUE)
saveRDS(the_g, paste0('/Users/abraham/Library/CloudStorage/Box/Redundancy_Project/R/Graph Matrices/HCSF_File_', i, ".RDS"))
#Compute Strength, Closeness, and Betweenness
hcsf_all[i,, "strength"] <- strength(the_g)
hcsf_all[i,,"closeness"] <- closeness(the_g, weights = 1/round(abs(E(the_g)$weight),2), normalized = TRUE)
hcsf_all[i,,"betweenness"] <- betweenness(the_g, weights = 1/(abs(E(the_g)$weight)), normalized = FALSE)
if (!is.null(hcsf_all)) {
saveRDS(hcsf_all, paste0('/Users/abraham/Library/CloudStorage/Box/Redundancy_Project/R/Metrics/HCSF_', i , ".RDS"))
prev_file <- paste0('/Users/abraham/Library/CloudStorage/Box/Redundancy_Project/R/Metrics/HCSF_', i - 1, ".RDS")
if (file.exists(prev_file)) {
file.remove(prev_file)
}
} else {
message(paste0("Ope, this run had an error. Preserving simulation as of Replication ", i))
}
# Compute clone inclusion difference in redundancy network
total_strength <- strength(the_g)
connections_2_clone <- E(the_g)$weight[which(grepl("Clone", as_ids(E(the_g))))]
hcsf_wc[i,,"strength"] <- (total_strength[(nv+1):(2*nv)] - connections_2_clone) - total_strength[1:nv]
clone_edges <- E(the_g)[grepl("Clone", as_ids(E(the_g)))]
g_no_clone <- delete_edges(the_g, clone_edges)
closeness_wc <- closeness(g_no_clone, normalized = TRUE, weights = 1/abs(E(g_no_clone)$weight))
closeness_wthc <- closeness(the_g, normalized = TRUE, weights = 1/abs(E(the_g)$weight))
hcsf_wc[i,,"closeness"] <- closeness_wc[(nv+1):(2*nv)] - closeness_wthc[1:nv]
betweenness_wc <- betweenness(g_no_clone, normalized = FALSE, weights = 1/abs(E(g_no_clone)$weight))
betweenness_wthc <- betweenness(the_g, normalized = FALSE,  weights = 1/abs(E(the_g)$weight))
hcsf_wc[i,,"betweenness" ] <- betweenness_wc[(nv+1):(2*nv)] - betweenness_wthc[1:nv]
}
hcsf_all
gitcreds_set()
library(gitcreds)
install.packages("gitcreds")
library(gitcreds)
gitcreds_set()
gitcreds_set()
git_credset()
git credential-osxkeychain get
git_credential-osxkeychain get
# Correlation matrix of the indicators excluding the redundant indicator
true_corr <- redun_corr[1:nv, 1:nv]
credential_helper_get()
library(credentials)
gitcreds_set()
git_credset()
library(gitcreds)
gitcreds_set()
use_github()
library(gitcreds)
use_github()
library(usethis)
